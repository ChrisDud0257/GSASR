
1. The first line of table reports the overall results of the whole function and the following lines reports the statistics of each line in the function.
2. The `hit perc` and `time perc` represent `hit percentage` and `time percentage`.
3. For memory, there exists four categories `mem inc`, `mem peak`, `gpu mem inc` and `gpu mem peak`. They denotes `cpu memory increasement`, `cpu memory peak`, `gpu memory increasement` and `gpu memory peak`. All the results are collected in the last run. The number in the increasement field denots the increasement of corresponding memory of each line (the first line is related to the whole function). Sometimes, the number of each line is far less of the number of the first line, which is valid since python may auto release the unused memory after the function execution. The number of each line in the peak filed is a simple sum of the numbers of above lines in the increasement field, which is used to demonstrate the possible maxinum memory usage in the function.
4. For any issue, please concact us via https://github.com/xtudbxk/lineprofiler or zhengqiang.zhang@hotmail.com
        args - base=ms, cuda_sync=True, gpuids=(0,), warmup=0
+--------+------+------------+--------------+----------+-----------+----------+----------+-------------+--------------+-----------------------------------------------------------------------------+
| lineno | hits |    time    | time per hit | hit perc | time perc | mem inc  | mem peak | gpu mem inc | gpu mem peak | sources                                                                     |
+--------+------+------------+--------------+----------+-----------+----------+----------+-------------+--------------+-----------------------------------------------------------------------------+
|   41   |  1   | 76.8299 ms |  76.8299 ms  |    -     |     -     | 0.902 MB | baseline |   3.500 MB  |   baseline   | def gaussiansplatting_render(sigmas, coords, colors, image_size):           |
|   42   |  1   | 0.0353 ms  |  0.0353 ms   | 14.286%  |   0.046%  | 0.000 MB | 0.000 MB |   0.000 MB  |   0.000 MB   |     sigmas = sigmas.contiguous() # (gs num, 3)                              |
|   43   |  1   | 0.0078 ms  |  0.0078 ms   | 14.286%  |   0.010%  | 0.000 MB | 0.000 MB |   0.000 MB  |   0.000 MB   |     coords = coords.contiguous() # (gs num, 2)                              |
|   44   |  1   | 0.0063 ms  |  0.0063 ms   | 14.286%  |   0.008%  | 0.000 MB | 0.000 MB |   0.000 MB  |   0.000 MB   |     colors = colors.contiguous() # (gs num, c)                              |
|   45   |  1   | 0.0063 ms  |  0.0063 ms   | 14.286%  |   0.008%  | 0.000 MB | 0.000 MB |   0.000 MB  |   0.000 MB   |     h, w = image_size[:2]                                                   |
|   46   |  1   | 0.0093 ms  |  0.0093 ms   | 14.286%  |   0.012%  | 0.000 MB | 0.000 MB |   0.000 MB  |   0.000 MB   |     c = colors.shape[-1]                                                    |
|   47   |  1   | 1.8306 ms  |  1.8306 ms   | 14.286%  |   2.383%  | 0.438 MB | 0.438 MB |   3.000 MB  |   3.000 MB   |     rendered_img = torch.zeros(h, w, c).to(colors.device).to(torch.float32) |
|   48   |  1   | 74.9344 ms |  74.9344 ms  | 14.286%  |  97.533%  | 0.465 MB | 0.902 MB |   0.000 MB  |   3.000 MB   |     return GSCUDA.apply(sigmas, coords, colors, rendered_img)               |
+--------+------+------------+--------------+----------+-----------+----------+----------+-------------+--------------+-----------------------------------------------------------------------------+
1. The first line of table reports the overall results of the whole function and the following lines reports the statistics of each line in the function.
2. The `hit perc` and `time perc` represent `hit percentage` and `time percentage`.
3. For memory, there exists four categories `mem inc`, `mem peak`, `gpu mem inc` and `gpu mem peak`. They denotes `cpu memory increasement`, `cpu memory peak`, `gpu memory increasement` and `gpu memory peak`. All the results are collected in the last run. The number in the increasement field denots the increasement of corresponding memory of each line (the first line is related to the whole function). Sometimes, the number of each line is far less of the number of the first line, which is valid since python may auto release the unused memory after the function execution. The number of each line in the peak filed is a simple sum of the numbers of above lines in the increasement field, which is used to demonstrate the possible maxinum memory usage in the function.
4. For any issue, please concact us via https://github.com/xtudbxk/lineprofiler or zhengqiang.zhang@hotmail.com
        args - base=ms, cuda_sync=True, gpuids=(0,), warmup=0
+--------+------+--------------+--------------+----------+-----------+----------+----------+-------------+--------------+-----------------------------------------------------------------------------+
| lineno | hits |     time     | time per hit | hit perc | time perc | mem inc  | mem peak | gpu mem inc | gpu mem peak | sources                                                                     |
+--------+------+--------------+--------------+----------+-----------+----------+----------+-------------+--------------+-----------------------------------------------------------------------------+
|   41   |  1   | 1175.7406 ms | 1175.7406 ms |    -     |     -     | 0.777 MB | baseline |  12.000 MB  |   baseline   | def gaussiansplatting_render(sigmas, coords, colors, image_size):           |
|   42   |  1   |  0.0304 ms   |  0.0304 ms   | 14.286%  |   0.003%  | 0.000 MB | 0.000 MB |   0.000 MB  |   0.000 MB   |     sigmas = sigmas.contiguous() # (gs num, 3)                              |
|   43   |  1   |  0.0069 ms   |  0.0069 ms   | 14.286%  |   0.001%  | 0.000 MB | 0.000 MB |   0.000 MB  |   0.000 MB   |     coords = coords.contiguous() # (gs num, 2)                              |
|   44   |  1   |  0.0064 ms   |  0.0064 ms   | 14.286%  |   0.001%  | 0.000 MB | 0.000 MB |   0.000 MB  |   0.000 MB   |     colors = colors.contiguous() # (gs num, c)                              |
|   45   |  1   |  0.0065 ms   |  0.0065 ms   | 14.286%  |   0.001%  | 0.000 MB | 0.000 MB |   0.000 MB  |   0.000 MB   |     h, w = image_size[:2]                                                   |
|   46   |  1   |  0.0099 ms   |  0.0099 ms   | 14.286%  |   0.001%  | 0.000 MB | 0.000 MB |   0.000 MB  |   0.000 MB   |     c = colors.shape[-1]                                                    |
|   47   |  1   |  1.2594 ms   |  1.2594 ms   | 14.286%  |   0.107%  | 0.133 MB | 0.133 MB |   3.000 MB  |   3.000 MB   |     rendered_img = torch.zeros(h, w, c).to(colors.device).to(torch.float32) |
|   48   |  1   | 1174.4211 ms | 1174.4211 ms | 14.286%  |  99.888%  | 0.645 MB | 0.777 MB |   0.000 MB  |   3.000 MB   |     return GSCUDA.apply(sigmas, coords, colors, rendered_img)               |
+--------+------+--------------+--------------+----------+-----------+----------+----------+-------------+--------------+-----------------------------------------------------------------------------+
1. The first line of table reports the overall results of the whole function and the following lines reports the statistics of each line in the function.
2. The `hit perc` and `time perc` represent `hit percentage` and `time percentage`.
3. For memory, there exists four categories `mem inc`, `mem peak`, `gpu mem inc` and `gpu mem peak`. They denotes `cpu memory increasement`, `cpu memory peak`, `gpu memory increasement` and `gpu memory peak`. All the results are collected in the last run. The number in the increasement field denots the increasement of corresponding memory of each line (the first line is related to the whole function). Sometimes, the number of each line is far less of the number of the first line, which is valid since python may auto release the unused memory after the function execution. The number of each line in the peak filed is a simple sum of the numbers of above lines in the increasement field, which is used to demonstrate the possible maxinum memory usage in the function.
4. For any issue, please concact us via https://github.com/xtudbxk/lineprofiler or zhengqiang.zhang@hotmail.com
        args - base=ms, cuda_sync=True, gpuids=(0,), warmup=0
+--------+------+---------------+--------------+----------+-----------+-----------+-----------+-------------+--------------+-----------------------------------------------------------------------------+
| lineno | hits |      time     | time per hit | hit perc | time perc |  mem inc  |  mem peak | gpu mem inc | gpu mem peak | sources                                                                     |
+--------+------+---------------+--------------+----------+-----------+-----------+-----------+-------------+--------------+-----------------------------------------------------------------------------+
|   41   |  10  | 11844.9229 ms | 1184.4923 ms |    -     |     -     | 20.227 MB |  baseline |  15.000 MB  |   baseline   | def gaussiansplatting_render(sigmas, coords, colors, image_size):           |
|   42   |  10  |   0.1342 ms   |  0.0134 ms   | 14.286%  |   0.001%  |  0.000 MB |  0.000 MB |   0.000 MB  |   0.000 MB   |     sigmas = sigmas.contiguous() # (gs num, 3)                              |
|   43   |  10  |   0.0654 ms   |  0.0065 ms   | 14.286%  |   0.001%  |  0.000 MB |  0.000 MB |   0.000 MB  |   0.000 MB   |     coords = coords.contiguous() # (gs num, 2)                              |
|   44   |  10  |   0.0618 ms   |  0.0062 ms   | 14.286%  |   0.001%  |  0.000 MB |  0.000 MB |   0.000 MB  |   0.000 MB   |     colors = colors.contiguous() # (gs num, c)                              |
|   45   |  10  |   0.0710 ms   |  0.0071 ms   | 14.286%  |   0.001%  |  0.000 MB |  0.000 MB |   0.000 MB  |   0.000 MB   |     h, w = image_size[:2]                                                   |
|   46   |  10  |   0.0803 ms   |  0.0080 ms   | 14.286%  |   0.001%  |  0.062 MB |  0.062 MB |   0.000 MB  |   0.000 MB   |     c = colors.shape[-1]                                                    |
|   47   |  10  |   7.2555 ms   |  0.7256 ms   | 14.286%  |   0.061%  | 19.105 MB | 19.168 MB |  30.000 MB  |  30.000 MB   |     rendered_img = torch.zeros(h, w, c).to(colors.device).to(torch.float32) |
|   48   |  10  | 11837.2547 ms | 1183.7255 ms | 14.286%  |  99.935%  |  1.059 MB | 20.227 MB |   0.000 MB  |  30.000 MB   |     return GSCUDA.apply(sigmas, coords, colors, rendered_img)               |
+--------+------+---------------+--------------+----------+-----------+-----------+-----------+-------------+--------------+-----------------------------------------------------------------------------+
1. The first line of table reports the overall results of the whole function and the following lines reports the statistics of each line in the function.
2. The `hit perc` and `time perc` represent `hit percentage` and `time percentage`.
3. For memory, there exists four categories `mem inc`, `mem peak`, `gpu mem inc` and `gpu mem peak`. They denotes `cpu memory increasement`, `cpu memory peak`, `gpu memory increasement` and `gpu memory peak`. All the results are collected in the last run. The number in the increasement field denots the increasement of corresponding memory of each line (the first line is related to the whole function). Sometimes, the number of each line is far less of the number of the first line, which is valid since python may auto release the unused memory after the function execution. The number of each line in the peak filed is a simple sum of the numbers of above lines in the increasement field, which is used to demonstrate the possible maxinum memory usage in the function.
4. For any issue, please concact us via https://github.com/xtudbxk/lineprofiler or zhengqiang.zhang@hotmail.com
        args - base=ms, cuda_sync=True, gpuids=(0,), warmup=0
+--------+------+---------------+--------------+----------+-----------+-----------+-----------+-------------+--------------+-----------------------------------------------------------------------------+
| lineno | hits |      time     | time per hit | hit perc | time perc |  mem inc  |  mem peak | gpu mem inc | gpu mem peak | sources                                                                     |
+--------+------+---------------+--------------+----------+-----------+-----------+-----------+-------------+--------------+-----------------------------------------------------------------------------+
|   41   |  10  | 11855.0900 ms | 1185.5090 ms |    -     |     -     | 20.242 MB |  baseline |  15.000 MB  |   baseline   | def gaussiansplatting_render(sigmas, coords, colors, image_size):           |
|   42   |  10  |   0.1263 ms   |  0.0126 ms   | 14.286%  |   0.001%  |  0.078 MB |  0.078 MB |   0.000 MB  |   0.000 MB   |     sigmas = sigmas.contiguous() # (gs num, 3)                              |
|   43   |  10  |   0.0632 ms   |  0.0063 ms   | 14.286%  |   0.001%  |  0.000 MB |  0.078 MB |   0.000 MB  |   0.000 MB   |     coords = coords.contiguous() # (gs num, 2)                              |
|   44   |  10  |   0.0588 ms   |  0.0059 ms   | 14.286%  |   0.000%  |  0.000 MB |  0.078 MB |   0.000 MB  |   0.000 MB   |     colors = colors.contiguous() # (gs num, c)                              |
|   45   |  10  |   0.0626 ms   |  0.0063 ms   | 14.286%  |   0.001%  |  0.000 MB |  0.078 MB |   0.000 MB  |   0.000 MB   |     h, w = image_size[:2]                                                   |
|   46   |  10  |   0.0747 ms   |  0.0075 ms   | 14.286%  |   0.001%  |  0.000 MB |  0.078 MB |   0.000 MB  |   0.000 MB   |     c = colors.shape[-1]                                                    |
|   47   |  10  |   7.0497 ms   |  0.7050 ms   | 14.286%  |   0.059%  | 19.078 MB | 19.156 MB |  30.000 MB  |  30.000 MB   |     rendered_img = torch.zeros(h, w, c).to(colors.device).to(torch.float32) |
|   48   |  10  | 11847.6547 ms | 1184.7655 ms | 14.286%  |  99.937%  |  0.820 MB | 19.977 MB |   0.000 MB  |  30.000 MB   |     return GSCUDA.apply(sigmas, coords, colors, rendered_img)               |
+--------+------+---------------+--------------+----------+-----------+-----------+-----------+-------------+--------------+-----------------------------------------------------------------------------+